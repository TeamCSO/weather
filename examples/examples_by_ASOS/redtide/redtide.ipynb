{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 패키지 로딩\n",
    "#============================================================\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import h2o\n",
    "import numpy as np\n",
    "import itertools \n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# 분석 환경 셋팅\n",
    "#============================================================\n",
    "sys.stdout.flush() #Python 메모리에 생성된 모든 객체 삭제(초기화)\n",
    "\n",
    "#============================================================\n",
    "# 작업 디렉토리 경로 확인\n",
    "#============================================================\n",
    "currentPath=os.getcwd()\n",
    "print('Current working dir : %s' % currentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# 기상 데이터 읽어오기 \n",
    "#============================================================\n",
    "ASOS = pd.read_csv(currentPath + \"/input/ASOS_imput.csv\", encoding='UTF-8') #loading weather data\n",
    "BUOY_DP = pd.read_csv(currentPath + \"/input/BUOY_DP_imput.csv\", encoding='UTF-8') #loading weather data\n",
    "HYCOM = pd.read_csv(currentPath + \"/input/SEA_IVs_hycom_all.csv\", encoding='UTF-8') #loading hycom data\n",
    "\n",
    "ASOS = ASOS.rename(columns = {\"WS_MAX\":\"WS_MAX_ASOS\"})\n",
    "BUOY_DP = BUOY_DP.rename(columns = {\"WS_MAX\":\"WS_MAX_BD\"})\n",
    "\n",
    "#=============================================================\n",
    "# 불러온 데이터 구조 확인하기\n",
    "#=============================================================\n",
    "ASOS\n",
    "BUOY_DP\n",
    "HYCOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 테이블 결합 및 확인 \n",
    "#=============================================================\n",
    "HYCOM['YYMMDD'] = pd.to_datetime(HYCOM['YYMMDD'], format='%Y-%m-%d')\n",
    "HYCOM[['year', 'month']] = HYCOM[['year', 'month']].apply(pd.to_numeric)\n",
    "HYCOM.dtypes\n",
    "\n",
    "ASOS['YYMMDD'] = pd.to_datetime(ASOS['YYMMDD'], format='%Y-%m-%d')\n",
    "ASOS[['year', 'month']] = ASOS[['year', 'month']].apply(pd.to_numeric)\n",
    "ASOS.dtypes\n",
    "\n",
    "BUOY_DP['YYMMDD'] = pd.to_datetime(BUOY_DP['YYMMDD'], format='%Y-%m-%d')\n",
    "BUOY_DP[['year', 'month']] = BUOY_DP[['year', 'month']].apply(pd.to_numeric)\n",
    "BUOY_DP.dtypes\n",
    "\n",
    "DT = pd.merge(HYCOM, ASOS, how='left', on=['HAEGU_NUM', 'YYMMDD', 'year', 'month'])\n",
    "DT = pd.merge(DT, BUOY_DP, how='left', on=['HAEGU_NUM', 'YYMMDD', 'year', 'month'])\n",
    "\n",
    "DT.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# 적조 데이터 읽어오기 \n",
    "#============================================================\n",
    "redtide = pd.read_csv(currentPath + \"/input/redtide.csv\", sep='\\t', encoding='UTF-8') #loading redtide data\n",
    "\n",
    "# column 수정\n",
    "redtide.rename(columns={redtide.columns[0]:\"YYMMDD\"}, inplace = True)\n",
    "redtide.rename(columns={redtide.columns[5]:\"LAT_r\"}, inplace = True)\n",
    "redtide.rename(columns={redtide.columns[6]:\"LON_r\"}, inplace = True)\n",
    "\n",
    "redtide['YYMMDD'] = pd.to_datetime(redtide['YYMMDD'], format='%Y%m%d')\n",
    "redtide['month'] = pd.to_numeric(redtide['YYMMDD'].dt.month)\n",
    "redtide['year'] = pd.to_numeric(redtide['YYMMDD'].dt.year)\n",
    "\n",
    "#============================================================\n",
    "# 불러온 데이터 구조 확인하기 \n",
    "#============================================================\n",
    "redtide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 해구 데이터 읽어오기\n",
    "#=============================================================\n",
    "HAEGU = pd.read_csv(currentPath + \"/input/SEA_latlon.csv\", sep='\\t', encoding='UTF-8') #loading redtide data\n",
    "HAEGU = HAEGU.sort_values(by=['HAEGU_NUM'])\n",
    "HAEGU['row_h'] = HAEGU.index + 1\n",
    "\n",
    "HAEGU.rename(columns={HAEGU.columns[1]:\"LAT_h\"}, inplace = True)\n",
    "HAEGU.rename(columns={HAEGU.columns[2]:\"LON_h\"}, inplace = True)\n",
    "\n",
    "#============================================================\n",
    "# 불러온 데이터 구조 확인하기 \n",
    "#============================================================\n",
    "HAEGU.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 테이블 결합 및 확인\n",
    "#=============================================================\n",
    "match=redtide[[\"LAT_r\",\"LON_r\"]].drop_duplicates()\n",
    "match[\"row_r\"]=match.index+1\n",
    "\n",
    "def expand_grid(data_dict):\n",
    "    rows = itertools.product(*data_dict.values())\n",
    "    return pd.DataFrame.from_records(rows, columns=data_dict.keys())\n",
    "tmp = expand_grid({'row_h' : HAEGU['row_h'], 'row_r' : match['row_r']})\n",
    "np.shape(tmp)[0]# nrow(match)*nrow(HAEGU)= 668*1318\n",
    "\n",
    "tmp = pd.merge(tmp, HAEGU, how='left', on=['row_h'])\n",
    "tmp = pd.merge(tmp, match, how='left', on=['row_r'])\n",
    "\n",
    "tmp['dist'] = np.hypot(tmp['LAT_h'].sub(tmp['LAT_r']), tmp['LON_h'].sub(tmp['LON_r']))\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "tmp = pysqldf(\"select HAEGU_NUM, LAT_h, LON_h, LAT_r, LON_r, min(dist) as dist from tmp group by row_r;\")\n",
    "redtide = pd.merge(redtide, tmp, how='left', on=['LAT_r','LON_r'])\n",
    "              \n",
    "redtide.info()\n",
    "redtide.head(5)\n",
    "\n",
    "#=============================================================\n",
    "# HAEGU, period 선택\n",
    "#=============================================================\n",
    "#start = datetime.datetime.strptime(\"2008-09-19\", \"%Y-%m-%d\").date()\n",
    "#end = datetime.datetime.strptime(\"2016-12-31\", \"%Y-%m-%d\").date()\n",
    "start = np.datetime64(\"2008-09-19\")\n",
    "end = np.datetime64(\"2016-12-31\")\n",
    "\n",
    "redtide = redtide.loc[pd.to_datetime(redtide['YYMMDD']) >= start]\n",
    "redtide = redtide.loc[pd.to_datetime(redtide['YYMMDD']) <= end]\n",
    "\n",
    "redtide = redtide[redtide['month'].isin([5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "redtide = redtide[redtide['HAEGU_NUM'].isin([97, 98, 99, 213, 214])]\n",
    "\n",
    "# 해구Num, 같은 날짜 여러 상태의 경우 Cochlo_YN값 MAX로 표출\n",
    "redtide = redtide.groupby(['HAEGU_NUM', 'YYMMDD']).max()['Cochlo_YN'].reset_index()\n",
    "redtide.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 기상 데이터, 적조 데이터 결합\n",
    "#=============================================================\n",
    "AB = pd.merge(DT, redtide, how='left', on=['YYMMDD', 'HAEGU_NUM'])\n",
    "AB['Cochlo_YN'] = AB['Cochlo_YN'].fillna(0)\n",
    "\n",
    "# 데이터 결측치 확인\n",
    "AB.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 데이터 전처리\n",
    "#=============================================================\n",
    "AB.describe()\n",
    "\n",
    "# 기상변수에서 NA값이 -999로 처리된 경우 확인\n",
    "AB[AB==-999]=np.nan\n",
    "\n",
    "# 결측치 처리\n",
    "AB = AB.fillna(AB.mean(numeric_only=True))\n",
    "\n",
    "# 결측치 확인\n",
    "AB.isnull().sum()\n",
    "\n",
    "AB = AB.sort_values(by=['HAEGU_NUM', 'year', 'YYMMDD'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 파생변수 생성\n",
    "#=============================================================\n",
    "# 7일 평균값을 구함\n",
    "AB['mean_AVG_EMP'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_EMP'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_SSH'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_SSH'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_SURFACE_SALINITY_TREND'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_SURFACE_SALINITY_TREND'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_SURFACE_TEMPERATURE_TREND'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_SURFACE_TEMPERATURE_TREND'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_SALINITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_SALINITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_SALINITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_SALINITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_SALINITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_SALINITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_SALINITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_SALINITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_SALINITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_SALINITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_SALINITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_SALINITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_SALINITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_SALINITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_SALINITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_SALINITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_SALINITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_SALINITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_SALINITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_SALINITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_SALINITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_SALINITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_SALINITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_SALINITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_SALINITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_SALINITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_SALINITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_SALINITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_SALINITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_SALINITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_SALINITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_SALINITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_TEMP_01'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_TEMP_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_TEMP_02'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_TEMP_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_TEMP_03'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_TEMP_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_TEMP_04'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_TEMP_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_TEMP_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_TEMP_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_TEMP_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_TEMP_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_TEMP_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_TEMP_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_TEMP_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_TEMP_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_TEMP_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_TEMP_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_TEMP_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_TEMP_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_TEMP_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_TEMP_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_TEMP_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_TEMP_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_TEMP_01'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_TEMP_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_TEMP_02'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_TEMP_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_TEMP_03'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_TEMP_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_TEMP_04'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_TEMP_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_U_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_U_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_U_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_U_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_U_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_U_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_U_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_U_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_U_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_U_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_U_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_U_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_U_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_U_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_U_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_U_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_U_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_U_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_U_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_U_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_U_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_U_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_U_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_U_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_U_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_U_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_U_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_U_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_U_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_U_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_U_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_U_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_V_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_V_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_V_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_V_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_V_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_V_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_AVG_V_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['AVG_V_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_V_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_V_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_V_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_V_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_V_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_V_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MAX_V_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MAX_V_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_V_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_V_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_V_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_V_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_V_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_V_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_MIN_V_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['MIN_V_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_V_VELOCITY_01'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_V_VELOCITY_01'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_V_VELOCITY_02'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_V_VELOCITY_02'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_V_VELOCITY_03'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_V_VELOCITY_03'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "AB['mean_STDEV_V_VELOCITY_04'] = AB.groupby(['HAEGU_NUM', 'year'])['STDEV_V_VELOCITY_04'].apply(lambda x : x.rolling(7).sum().shift(1)) / 7\n",
    "\n",
    "# 전처리 이전 변수 삭제\n",
    "AB.drop(['AVG_EMP', 'MAX_SSH', 'AVG_SURFACE_SALINITY_TREND', 'STDEV_SURFACE_TEMPERATURE_TREND', 'AVG_SALINITY_01', 'AVG_SALINITY_02'\n",
    ", 'AVG_SALINITY_03', 'AVG_SALINITY_04', 'MAX_SALINITY_01', 'MAX_SALINITY_02', 'MAX_SALINITY_03', 'MAX_SALINITY_04', 'MIN_SALINITY_01'\n",
    ", 'MIN_SALINITY_02', 'MIN_SALINITY_03', 'MIN_SALINITY_04', 'STDEV_SALINITY_01', 'STDEV_SALINITY_02', 'STDEV_SALINITY_03'\n",
    ", 'STDEV_SALINITY_04', 'AVG_TEMP_01', 'AVG_TEMP_02', 'AVG_TEMP_03', 'AVG_TEMP_04', 'MAX_TEMP_01', 'MAX_TEMP_02', 'MAX_TEMP_03'\n",
    ", 'MAX_TEMP_04', 'MIN_TEMP_01', 'MIN_TEMP_02', 'MIN_TEMP_03', 'MIN_TEMP_04', 'STDEV_TEMP_01', 'STDEV_TEMP_02', 'STDEV_TEMP_03'\n",
    ", 'STDEV_TEMP_04', 'AVG_U_VELOCITY_01', 'AVG_U_VELOCITY_02', 'AVG_U_VELOCITY_03', 'AVG_U_VELOCITY_04', 'MAX_U_VELOCITY_01'\n",
    ", 'MAX_U_VELOCITY_02', 'MAX_U_VELOCITY_03', 'MAX_U_VELOCITY_04', 'MIN_U_VELOCITY_01', 'MIN_U_VELOCITY_02', 'MIN_U_VELOCITY_03'\n",
    ", 'MIN_U_VELOCITY_04', 'STDEV_U_VELOCITY_01', 'STDEV_U_VELOCITY_02', 'STDEV_U_VELOCITY_03', 'STDEV_U_VELOCITY_04'\n",
    ", 'AVG_V_VELOCITY_01', 'AVG_V_VELOCITY_02', 'AVG_V_VELOCITY_03', 'AVG_V_VELOCITY_04', 'MAX_V_VELOCITY_01', 'MAX_V_VELOCITY_02'\n",
    ", 'MAX_V_VELOCITY_03', 'MAX_V_VELOCITY_04', 'MIN_V_VELOCITY_01', 'MIN_V_VELOCITY_02', 'MIN_V_VELOCITY_03', 'MIN_V_VELOCITY_04'\n",
    ", 'STDEV_V_VELOCITY_01', 'STDEV_V_VELOCITY_02', 'STDEV_V_VELOCITY_03', 'STDEV_V_VELOCITY_04'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 14일 평균값을 구함\n",
    "AB['mean_TA_MAX'] = AB.groupby(['HAEGU_NUM', 'year'])['TA_MAX'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_WS_MAX_ASOS'] = AB.groupby(['HAEGU_NUM', 'year'])['WS_MAX_ASOS'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_WS_MAX_BD'] = AB.groupby(['HAEGU_NUM', 'year'])['WS_MAX_BD'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_WS_INS'] = AB.groupby(['HAEGU_NUM', 'year'])['WS_INS'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_WS_MIN'] = AB.groupby(['HAEGU_NUM', 'year'])['WS_MIN'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_HM_AVG'] = AB.groupby(['HAEGU_NUM', 'year'])['HM_AVG'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_EV_L'] = AB.groupby(['HAEGU_NUM', 'year'])['EV_L'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_PA_AVG'] = AB.groupby(['HAEGU_NUM', 'year'])['PA_AVG'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_PS_MIN'] = AB.groupby(['HAEGU_NUM', 'year'])['PS_MIN'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "AB['mean_WH_MAX'] = AB.groupby(['HAEGU_NUM', 'year'])['WH_MAX'].apply(lambda x : x.rolling(14).sum().shift(1)) / 14\n",
    "\n",
    "# 전처리 이전 변수 삭제\n",
    "AB.drop(['TA_MAX', 'WS_MAX_ASOS', 'WS_MAX_BD', 'WS_INS', 'WS_MIN', 'HM_AVG', 'EV_L', 'PA_AVG', 'PS_MIN', 'WH_MAX'], axis='columns', inplace=True)\n",
    "\n",
    "# 14일 누적치를 구함\n",
    "AB['sum_SS_DAY'] = AB.groupby(['HAEGU_NUM', 'year'])['SS_DAY'].apply(lambda x : x.rolling(14).sum().shift(1))\n",
    "AB['sum_RN_DAY'] = AB.groupby(['HAEGU_NUM', 'year'])['RN_DAY'].apply(lambda x : x.rolling(14).sum().shift(1))\n",
    "AB['sum_SI_DAY'] = AB.groupby(['HAEGU_NUM', 'year'])['SI_DAY'].apply(lambda x : x.rolling(14).sum().shift(1))\n",
    "AB['sum_RN_DUR'] = AB.groupby(['HAEGU_NUM', 'year'])['RN_DUR'].apply(lambda x : x.rolling(14).sum().shift(1))\n",
    "AB.drop(['SS_DAY', 'RN_DAY', 'SI_DAY', 'RN_DUR'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time interval create\n",
    "AB['Cochlo_YN'] = AB.groupby(['HAEGU_NUM', 'year'])['Cochlo_YN'].shift(-7)\n",
    "\n",
    "#start = datetime.datetime.strptime(\"2008-10-04\", \"%Y-%m-%d\").date()\n",
    "#end = datetime.datetime.strptime(\"2016-12-31\", \"%Y-%m-%d\").date()\n",
    "start = np.datetime64(\"2008-10-04\")\n",
    "end = np.datetime64(\"2016-12-31\")\n",
    "\n",
    "AB = AB.loc[pd.to_datetime(AB['YYMMDD']) >= start]\n",
    "AB = AB.loc[pd.to_datetime(AB['YYMMDD']) <= end]\n",
    "\n",
    "AB = AB[AB['month'].isin([5, 6, 7, 8, 9, 10, 11])]\n",
    "\n",
    "#======================================================================================================\n",
    "#메모리 용량 줄이기\n",
    "#======================================================================================================\n",
    "del(start, end)\n",
    "del(ASOS,BUOY_DP,DT,HAEGU,HYCOM,redtide,tmp,match)\n",
    "\n",
    "AB.info()\n",
    "AB.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================================================\n",
    "# 분석\n",
    "#=============================================================\n",
    "h2o.init(max_mem_size = \"4G\", nthreads = 1)\n",
    "h2o.remove_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting AB data\n",
    "dataXY = AB\n",
    "dataXY = dataXY.drop(['HAEGU_NUM', 'YYMMDD', 'month', 'year'], axis=1)\n",
    "dataXY = dataXY.rename(columns = {\"Cochlo_YN\":\"Y\"})\n",
    "dataXY.reset_index(drop=True, inplace=True)\n",
    "dataXY.info()\n",
    "\n",
    "# train, valid, test 데이터 분리\n",
    "## split to train, valid, test \n",
    "dataXY = h2o.H2OFrame(dataXY)\n",
    "train_data, valid_data, test_data = dataXY.split_frame(ratios=[0.7,0.15], seed=1111)\n",
    "\n",
    "## 독립변수, 종속변수 설정(x: 독립변수, y: 종속변수)\n",
    "x = dataXY.columns\n",
    "x.remove('Y')\n",
    "y='Y'\n",
    "\n",
    "train_data['Y'] = train_data['Y'].asfactor()\n",
    "valid_data['Y'] = valid_data['Y'].asfactor()\n",
    "test_data['Y'] = test_data['Y'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 모형 튜닝 자동화\n",
    "# -----------------------------------------------------------------------------\n",
    "# cartesian grid search \n",
    "# -----------------------------------------------------------------------------\n",
    "hyper_parameters = {'max_depth': [4, 6, 8, 12, 16, 20]}\n",
    "\n",
    "# 조합 모형 돌리기\n",
    "m = H2OGridSearch(H2ORandomForestEstimator,\n",
    "                  hyper_params=hyper_parameters,\n",
    "                  search_criteria={'strategy': \"Cartesian\"},\n",
    "                  grid_id='RF_depth_grid')\n",
    "\n",
    "m.train(x = x,\n",
    "        y = y,\n",
    "        training_frame = train_data,\n",
    "        validation_frame = valid_data,\n",
    "        ntrees = 10000,\n",
    "        stopping_rounds = 5,\n",
    "        stopping_tolerance = 1e-4,\n",
    "        stopping_metric = 'AUC',\n",
    "        score_tree_interval = 5,\n",
    "        seed=1111)\n",
    "\n",
    "# AUC가 높은 순으로 정렬하기\n",
    "sortedGrid = m.get_grid(sort_by='auc', decreasing=True)\n",
    "\n",
    "print('===== sortedGrid =====')\n",
    "print(sortedGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 모형 튜닝 자동화\n",
    "minDepth = 12\n",
    "maxDepth = 16\n",
    "\n",
    "# options for grid search \n",
    "max_runtime_secs = 60*10\n",
    "max_models = 100\n",
    "\n",
    "# random grid search \n",
    "hyper_params = {\n",
    "    'max_depth': list(range(minDepth, maxDepth + 1)),\n",
    "    'sample_rate': [i * 0.01 for i in range(20, 100 + 1)],\n",
    "    'col_sample_rate_per_tree': [i * 0.01 for i in range(20, 100 + 1)],\n",
    "    'col_sample_rate_change_per_level': [i * 0.01 for i in range(90, 110 + 1)],\n",
    "    'min_rows': [1,5,10,20,50,100],\n",
    "    'min_split_improvement': [0,1e-8,1e-6,1e-4],\n",
    "    'histogram_type': ['UniformAdaptive', 'QuantilesGlobal', 'RoundRobin']\n",
    "}\n",
    "\n",
    "search_criteria = {\n",
    "    'strategy': \"RandomDiscrete\",\n",
    "    'max_runtime_secs': max_runtime_secs,\n",
    "    'max_models': max_models\n",
    "}\n",
    "\n",
    "grid = H2OGridSearch(H2ORandomForestEstimator\n",
    "                     , hyper_params=hyper_parameters\n",
    "                     , search_criteria=search_criteria\n",
    "                     , grid_id='RF_grid')\n",
    "grid.train(\n",
    "      x = x\n",
    "    , y = y\n",
    "    , training_frame = train_data\n",
    "    , validation_frame = valid_data\n",
    "    , ntrees = 10000\n",
    "    , stopping_rounds = 5\n",
    "    , stopping_tolerance = 1e-4\n",
    "    , stopping_metric = 'AUC'\n",
    "    , score_tree_interval = 5\n",
    "    , seed = 1111\n",
    ")\n",
    "\n",
    "# AUC가 높은 순으로 정렬하기\n",
    "sortedGrid = grid.get_grid(sort_by='auc', decreasing=True)\n",
    "RF_AB_Tune = h2o.get_model(sortedGrid.model_ids[1])\n",
    "print(RF_AB_Tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#======================================================================================================\n",
    "# forecast\n",
    "#======================================================================================================\n",
    "pred= RF_AB_Tune.predict(test_data)\n",
    "pred=pred.as_data_frame()\n",
    "test_data=test_data.as_data_frame()\n",
    "\n",
    "pred = pd.concat([pred['predict'], pred['p1'], test_data['Y']], axis=1)\n",
    "pred.columns = ['Yhat','p1','Y']\n",
    "\n",
    "#confusion matrix\n",
    "print(confusion_matrix(pred['Yhat'],pred['Y']),\n",
    "      classification_report(pred['Yhat'],pred['Y']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
